{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import List, Tuple, Dict\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable annoying warnings from gensim\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define nontrivial polish language grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "NONTERMINALS = {\n",
    "    'S': [\n",
    "        ('VERB_PHRASE_IMPS',),\n",
    "        ('VERB_PHRASE_IMPS', 'CONJ', 'VERB_PHRASE_IMPS'),\n",
    "        ('NOM_PHRASE_SG_M', 'VERB_PHRASE_SG_FIN_M_TER'),\n",
    "        ('NOM_PHRASE_SG_M', 'VERB_PHRASE_SG_FIN_M_TER',\n",
    "         'CONJ', 'VERB_PHRASE_SG_FIN_M_TER'),\n",
    "        ('NOM_PHRASE_SG_M', 'VERB_PHRASE_SG_FIN_M_TER',\n",
    "         'CONJ', 'NOM_PHRASE_SG_M', 'VERB_PHRASE_SG_FIN_M_TER'),\n",
    "    ],\n",
    "    'VERB_PHRASE_IMPS': [\n",
    "        ('VERB_IMPS',),\n",
    "        ('ADV', 'VERB_IMPS'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_SG_M1'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_PL_F'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_PL_N2'),\n",
    "        ('ADV', 'VERB_IMPS', 'ACC_PHRASE_SG_M1'),\n",
    "        ('ADV', 'VERB_IMPS', 'ACC_PHRASE_PL_F'),\n",
    "        ('ADV', 'VERB_IMPS', 'ACC_PHRASE_PL_N2'),\n",
    "        \n",
    "    ],\n",
    "    'VERB_PHRASE_SG_FIN_M_TER': [\n",
    "        ('VERB_SG_FIN_M_TER',),\n",
    "        ('ADV', 'VERB_SG_FIN_M_TER'),\n",
    "        ('VERB_SG_FIN_M_TER', 'ACC_PHRASE_SG_M1'),\n",
    "        ('VERB_SG_FIN_M_TER', 'ACC_PHRASE_PL_F'),\n",
    "        ('VERB_SG_FIN_M_TER', 'ACC_PHRASE_PL_N2'),\n",
    "        ('ADV', 'VERB_SG_FIN_M_TER', 'ACC_PHRASE_SG_M1'),\n",
    "        ('ADV', 'VERB_SG_FIN_M_TER', 'ACC_PHRASE_PL_F'),\n",
    "        ('ADV', 'VERB_SG_FIN_M_TER', 'ACC_PHRASE_PL_N2'),\n",
    "    ],\n",
    "    'NOM_PHRASE_SG_M': [\n",
    "        ('SUBST_SG_NOM_M',),\n",
    "        ('SUBST_SG_NOM_M', 'PREP_ACC_PHRASE'),\n",
    "        ('ADJ_PHRASE_SG_NOM_M', 'SUBST_SG_NOM_M'),\n",
    "        ('ADJ_PHRASE_SG_NOM_M', 'SUBST_SG_NOM_M', 'PREP_ACC_PHRASE'),\n",
    "    ],\n",
    "    'ACC_PHRASE_SG_M1': [\n",
    "        ('SUBST_SG_ACC_M1',),\n",
    "        ('ADJ_PHRASE_SG_ACC_M1', 'SUBST_SG_ACC_M1',),\n",
    "    ],\n",
    "    'ACC_PHRASE_PL_F': [\n",
    "        ('SUBST_PL_ACC_F',),\n",
    "        ('ADJ_PHRASE_PL_ACC_F_N2', 'SUBST_PL_ACC_F'),\n",
    "    ],\n",
    "    'ACC_PHRASE_PL_N2': [\n",
    "        ('SUBST_PL_ACC_N2',),\n",
    "        ('ADJ_PHRASE_PL_ACC_F_N2', 'SUBST_PL_ACC_N2'),\n",
    "    ],\n",
    "    'ADJ_PHRASE_SG_NOM_M': [\n",
    "        ('ADJ_SG_NOM_M',),\n",
    "        ('ADJ_SG_NOM_M', 'ADJ_SG_NOM_M'),\n",
    "    ],\n",
    "    'ADJ_PHRASE_SG_ACC_M1': [\n",
    "        ('ADJ_SG_ACC_M1',),\n",
    "        ('ADJ_SG_ACC_M1', 'ADJ_SG_ACC_M1'),\n",
    "    ],\n",
    "    'ADJ_PHRASE_PL_ACC_F_N2': [\n",
    "        ('ADJ_PL_ACC_F_N2',),\n",
    "        ('ADJ_PL_ACC_F_N2', 'ADJ_PL_ACC_F_N2'),\n",
    "    ],\n",
    "    'PREP_ACC_PHRASE': [\n",
    "        ('PREP_ACC', 'ACC_PHRASE_SG_M1'),\n",
    "        ('PREP_ACC', 'ACC_PHRASE_PL_F'),\n",
    "        ('PREP_ACC', 'ACC_PHRASE_PL_N2'),\n",
    "    ],\n",
    "    \n",
    "    # Productions with terminals\n",
    "    'VERB_SG_FIN_M_TER': [('verb:fin:sg:ter.*:refl',)],\n",
    "    'VERB_IMPS': [('verb:imps',)],\n",
    "    'SUBST_SG_NOM_M': [('subst:sg:nom:m',)],\n",
    "    'SUBST_SG_ACC_M1': [('subst:sg:acc:m1',)],\n",
    "    'SUBST_PL_ACC_F': [('subst:pl:acc:f',)],\n",
    "    'SUBST_PL_ACC_N2': [('subst:pl:acc:n2',)],\n",
    "    'ADJ_SG_NOM_M': [('adj:sg:nom.voc:m1.m2.m3',)],\n",
    "    'ADJ_SG_ACC_M1': [('adj:sg:acc:m1',)],\n",
    "    'ADJ_PL_ACC_F_N2': [('adj:pl:acc:m2.m3.f.n1.n2.p2.p3',)],\n",
    "    'ADV': [('adv:',)],\n",
    "    'PREP_ACC': [('prep:acc',)],\n",
    "    'CONJ': [('^conj$',)],\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMINALS = (\n",
    "    'verb:fin:sg:ter.*:refl',\n",
    "    'verb:imps',\n",
    "    'subst:sg:nom:m',\n",
    "    'subst:sg:acc:m1',\n",
    "    'subst:pl:acc:f',\n",
    "    'subst:pl:acc:n2',\n",
    "    'adj:sg:nom.voc:m1.m2.m3',\n",
    "    'adj:sg:acc:m1',\n",
    "    'adj:pl:acc:m2.m3.f.n1.n2.p2.p3',\n",
    "    'adv:',\n",
    "    'prep:acc',\n",
    "    '^conj$',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoNonterminal(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TooLongSent(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbol:\n",
    "    def __init__(self, symbol: str):\n",
    "        self.symbol = symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Terminal(Symbol):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nonterminal(Symbol):\n",
    "    def __init__(self, symbol: str, productions: List[Symbol]):\n",
    "        super().__init__(symbol)\n",
    "        self.productions = productions\n",
    "        \n",
    "    def production(self) -> Tuple[Symbol]:\n",
    "\n",
    "        def create_new_symbol(symbol) -> Symbol:\n",
    "           if symbol in NONTERMINALS:\n",
    "               return Nonterminal(symbol, NONTERMINALS[symbol])\n",
    "           else:\n",
    "               return Terminal(symbol)\n",
    "        \n",
    "        # Draw the production\n",
    "        rand_prod_ind = np.random.choice(len(self.productions))\n",
    "        rand_prod = self.productions[rand_prod_ind]\n",
    "            \n",
    "        return list(map(create_new_symbol, rand_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    \n",
    "    def expand_terminal(self, symbols: List[Symbol]) -> List:        \n",
    "\n",
    "        # Extract nonterminals\n",
    "        nonterminals = [symbol for symbol in symbols\n",
    "                        if isinstance(symbol, Nonterminal)]\n",
    "            \n",
    "        if not nonterminals:\n",
    "            raise NoNonterminal\n",
    "            \n",
    "        # Expand random nonterminal\n",
    "        expand_ind = np.random.choice(len(nonterminals))\n",
    "        nonterminal = nonterminals[expand_ind]\n",
    "        new_symbols = nonterminal.production()\n",
    "            \n",
    "        # Swap nonterminal with new symbols\n",
    "        nonterminals_processed = 0\n",
    "        for ind in range(len(symbols)):\n",
    "            if isinstance(symbols[ind], Nonterminal):\n",
    "                nonterminals_processed += 1\n",
    "                    \n",
    "                if nonterminals_processed-1 == expand_ind:\n",
    "                        \n",
    "                    # Delete the old nonterminal\n",
    "                    symbols.pop(ind)\n",
    "                                \n",
    "                    # Insert new ones\n",
    "                    symbols = symbols[:ind] + new_symbols + symbols[ind:]\n",
    "\n",
    "        return symbols\n",
    "    \n",
    "    def symbols_to_strings(self, symbols: List[Symbol]) -> List:\n",
    "        return [symbol.symbol for symbol in symbols]\n",
    "        \n",
    "    def gen_terminals(self, start_symbol: Symbol) -> List:\n",
    "        symbols = [start_symbol]\n",
    "        \n",
    "        # Expand until there is any nonterminal in the symbols\n",
    "        while True:\n",
    "            try:\n",
    "                symbols = self.expand_terminal(symbols)\n",
    "            except NoNonterminal:\n",
    "                return self.symbols_to_strings(symbols)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some sentence schemas and group them by the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schemas(n_iter: int = 1000, schemas: Dict = {}) -> Dict:\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        start_symbol = Nonterminal('S', NONTERMINALS['S'])\n",
    "        \n",
    "        schema = tuple(gen.gen_terminals(start_symbol))\n",
    "        schema_len = len(schema)\n",
    "        \n",
    "        # Update schemas\n",
    "        if schema_len in schemas:\n",
    "            schemas[schema_len].add(schema)\n",
    "        else:\n",
    "            schemas[schema_len] = {schema}\n",
    "            \n",
    "    # Map sets to tuples to enable drawing\n",
    "    schemas = {key: tuple(val) for key, val in schemas.items()}\n",
    "            \n",
    "    return schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('adv:', 'verb:imps', 'subst:sg:acc:m1'),\n",
       " ('verb:imps', 'adj:sg:acc:m1', 'subst:sg:acc:m1'),\n",
       " ('verb:imps', 'adj:pl:acc:m2.m3.f.n1.n2.p2.p3', 'subst:pl:acc:f'),\n",
       " ('subst:sg:nom:m', 'adv:', 'verb:fin:sg:ter.*:refl'),\n",
       " ('verb:imps', '^conj$', 'verb:imps'),\n",
       " ('subst:sg:nom:m', 'verb:fin:sg:ter.*:refl', 'subst:pl:acc:n2'),\n",
       " ('adv:', 'verb:imps', 'subst:pl:acc:f'),\n",
       " ('subst:sg:nom:m', 'verb:fin:sg:ter.*:refl', 'subst:sg:acc:m1'),\n",
       " ('adv:', 'verb:imps', 'subst:pl:acc:n2'),\n",
       " ('verb:imps', 'adj:pl:acc:m2.m3.f.n1.n2.p2.p3', 'subst:pl:acc:n2'),\n",
       " ('adj:sg:nom.voc:m1.m2.m3', 'subst:sg:nom:m', 'verb:fin:sg:ter.*:refl'),\n",
       " ('subst:sg:nom:m', 'verb:fin:sg:ter.*:refl', 'subst:pl:acc:f'))"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemas = create_schemas()\n",
    "\n",
    "# Show some schemas\n",
    "schemas[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the grammar categories found in the grammar schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolimorfGen:\n",
    "    POLIMORF_PATH = './data/polimorfologik-2.1.txt'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.grammar_cats = dict((terminal, [])\n",
    "                                  for terminal in TERMINALS)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        with open(self.POLIMORF_PATH) as f:\n",
    "            yield from f\n",
    "            \n",
    "    def find_terminal_occ(self, line: str):\n",
    "        \"\"\"\n",
    "        Search for each pattern (terminal)\n",
    "        in the line of the polimorfologik file\n",
    "        \"\"\"\n",
    "        \n",
    "        base, token, grammar_cats = line.split(';')\n",
    "        \n",
    "        for terminal in self.grammar_cats:\n",
    "            pattern = re.compile(terminal)\n",
    "        \n",
    "            if pattern.search(grammar_cats):\n",
    "                self.grammar_cats[terminal].append((base, token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polimorf = PolimorfGen()\n",
    "\n",
    "# Extract the categories\n",
    "for line in polimorf:\n",
    "    polimorf.find_terminal_occ(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some sentences of length n without using the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentGen:\n",
    "    def rand_schema(self, n: int) -> Tuple:\n",
    "\n",
    "        # Draw the sentence schema\n",
    "        try:\n",
    "            schemas_n_len = schemas[n]\n",
    "            return random.choice(schemas_n_len)\n",
    "        except KeyError:\n",
    "            raise TooLongSent\n",
    "\n",
    "    def core_sent_gen(self, n: int) -> Tuple:\n",
    "        try:\n",
    "            schema = self.rand_schema(n)\n",
    "            \n",
    "            # Draw the tokens\n",
    "            tokens_with_bases = [random.choice(polimorf.grammar_cats[category])\n",
    "                                 for category in schema]\n",
    "\n",
    "            bases, tokens = list(zip(*tokens_with_bases))\n",
    "\n",
    "            return ' '.join(tokens)\n",
    "        except TooLongSent:\n",
    "            print('Sentence too long')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_gen = SentGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nierozbielały zamachowiec zeszarpie więc wykomentuje'"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ikt niezjawiskowo podtrzyma alić niegrzybowsko mistycyzuje'"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wjadano niedolnoniemieckie jednonarodowościowe żołędności póty upośledzono nielepowości'"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'współbrzmienny niepółfonetyczny puaz popod grząskie magnetosferyczne odwapnienia niekusicielsko skameralizuje'"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hydrant po nienapotne niespadkowe następstwa pysznicko stropikalizuje góreckie niemaoryskie bezcześci jakokolwiek niestaroczesny nieborowiczkowski Strumph-Wojtkiewicz przed hydrazynowego reeksportera prześpiewuje nieskulskie swoje'"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence too long\n"
     ]
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Word2Vec struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusGen:\n",
    "    CORPUS_PATH = './data/task3_train_segmented.txt'\n",
    "    \n",
    "    def __init__(self, n_sent):\n",
    "        self.n_sent = n_sent\n",
    "    \n",
    "    def __iter__(self):\n",
    "        with open(self.CORPUS_PATH) as f:\n",
    "            for line, _ in zip(f, range(self.n_sent)):\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./data/word2vec.model'):\n",
    "    # Perform the embeddings only during the first session \n",
    "    \n",
    "    sentences = CorpusGen(10_000_000)\n",
    "    model = Word2Vec(sentences, min_count=1)\n",
    "    model.save('./data/word2vec.model')\n",
    "else:\n",
    "    # The model exists\n",
    "    \n",
    "    # Gensim fails in case of loading the model for the second time\n",
    "    try:\n",
    "        model\n",
    "    except NameError:\n",
    "        model = Word2Vec.load('./data/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640650"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate thematical sentences from the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = (\n",
    "    ('malina', 'koszyk', 'zazdrość', 'morderstwo'),\n",
    "    ('programowanie', 'błąd', 'zmienna', 'deklaracja'),\n",
    "    ('lotniskowiec', 'łódź', 'podwodny',\n",
    "     'tonąć', 'atak', 'torpeda', 'ocean'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSentGen(SentGen):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def choose_best_token(self, tokens: List, topic: Tuple) -> str:\n",
    "        \n",
    "        # Draw the topic token\n",
    "        topic_token = random.choice(topic)\n",
    "        \n",
    "        base_token_similarities = {pair: 0 for pair in tokens}\n",
    "    \n",
    "        def update_sims(pair: Tuple, token: str) -> Dict:\n",
    "            if token in self.model.wv.vocab:\n",
    "                base_token_similarities[pair] +=\\\n",
    "                    model.wv.similarity(token, topic_token)\n",
    "    \n",
    "        # For each pair similarity is a sum of\n",
    "        # similarity(base, topic_token) and similarity(token, topic_word)\n",
    "        for base, token in base_token_similarities:\n",
    "            update_sims((base, token), base)\n",
    "            update_sims((base, token), token)\n",
    "            \n",
    "        best_base, best_token = max(base_token_similarities.items(),\n",
    "                                    key=itemgetter(1))[0]\n",
    "                    \n",
    "        return best_token\n",
    "        \n",
    "    def topic_sent_gen(self, n: int, topic: Tuple,\n",
    "                       n_to_choose: int = 1000) -> str:\n",
    "        try:\n",
    "            schema = self.rand_schema(n)\n",
    "            \n",
    "            categories = [random.choices(polimorf.grammar_cats[category],\n",
    "                                         k=n_to_choose)\n",
    "                          for category in schema]\n",
    "            \n",
    "            topic_sent = [self.choose_best_token(category, topic)\n",
    "                          for category in categories]\n",
    "            \n",
    "            return topic_sent\n",
    "            \n",
    "        except TooLongSent:\n",
    "            print('Sentence too long')\n",
    "            \n",
    "    def topic_sent_gen_n_times(self, n: int, topic: Tuple,\n",
    "                               n_to_choose: int = 1000,\n",
    "                               n_times: int = 100) -> List:\n",
    "        \n",
    "        sents = [self.topic_sent_gen(n, topic, n_to_choose)\n",
    "                 for _ in range(n_times)]\n",
    "        \n",
    "        return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sent_gen = TopicSentGen(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gwałcono', 'ylang-ylang', 'tedy', 'złorzeczono', 'czerwienie']"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(5, TOPICS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pijany',\n",
       " 'Borówka',\n",
       " 'co',\n",
       " 'grafiki',\n",
       " 'mikro',\n",
       " 'łuszczy',\n",
       " 'odchylenia',\n",
       " 'więc',\n",
       " 'pewnie',\n",
       " 'obliczy']"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(10, TOPICS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['świt',\n",
       " 'popod',\n",
       " 'rwące',\n",
       " 'minowe',\n",
       " 'działka',\n",
       " 'spogląda',\n",
       " 'tłuste',\n",
       " 'frontalne',\n",
       " 'podwodne',\n",
       " 'jakoż',\n",
       " 'nieprzyjacielski',\n",
       " 'ponton',\n",
       " 'popod',\n",
       " 'Yamahy',\n",
       " 'zestrzeli']"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(15, TOPICS[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best topic sent with Positive Pointwise Mutual Information (PPMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unigrams and bigrams structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGrams:\n",
    "\n",
    "    DATA_PATH = './data/poleval_2grams.txt'\n",
    "\n",
    "    def create_bigrams_unigrams(self, k: int = 100) -> Tuple:\n",
    "        \n",
    "        unigrams, bigrams = {}, {}\n",
    "        \n",
    "        def update_unigrams(token: str, freq: str) -> None:\n",
    "            if token in unigrams:\n",
    "                unigrams[token] += int(freq)\n",
    "            else:\n",
    "                unigrams[token] = int(freq)\n",
    "                \n",
    "        def update_bigrams(predecesor: str, successor: str,\n",
    "                           freq: str) -> None:\n",
    "            bigrams[(predecesor, successor)] = int(freq)\n",
    "\n",
    "        with open(self.DATA_PATH) as poleval:\n",
    "            for line in poleval:\n",
    "                freq, predecesor, successor = line.split()\n",
    "\n",
    "                # Update bigrams ans unigrams\n",
    "                if int(freq) >= k:\n",
    "                    update_bigrams(predecesor, successor, freq)\n",
    "                    update_unigrams(predecesor, freq)\n",
    "                    update_unigrams(successor, freq)\n",
    "\n",
    "        return unigrams, bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams = ngrams.create_bigrams_unigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':': 1701656,\n",
       " 'dalszego': 15414,\n",
       " 'i': 12077277,\n",
       " 'prowadzenia': 76467,\n",
       " 'richard': 1695}"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of unigrams\n",
    "dict(list(unigrams.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(':', 'richard'): 104,\n",
       " ('bo', 'chcemy'): 247,\n",
       " ('dalszego', 'prowadzenia'): 349,\n",
       " ('i', 'stosunek'): 137,\n",
       " ('określonych', 'ustawą'): 599}"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of bigrams\n",
    "dict(list(bigrams.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMI:\n",
    "    def __init__(self, unigrams: Dict, bigrams: Dict):\n",
    "        self.unigrams = unigrams\n",
    "        self.bigrams = bigrams\n",
    "    \n",
    "    def measure_pmi(self, sentence: List) -> float:\n",
    "        predecesors = sentence.copy()\n",
    "        successors = sentence.copy()\n",
    "        \n",
    "        predecesors.insert(0, '<BOS>')\n",
    "        successors.append('<EOS>')\n",
    "        \n",
    "        def PMI(predecesor: str, successor: str) -> float:\n",
    "            numerator = bigrams.get((predecesor, successor), 1.)\n",
    "            denominator = unigrams.get(predecesor, 1.) *\\\n",
    "                          unigrams.get(successor, 1.)\n",
    "            \n",
    "            return np.log(numerator / denominator)\n",
    "        \n",
    "        sent_bigrams = list(zip(predecesors, successors))\n",
    "        \n",
    "        pmi = sum([PMI(predecesor, successor)\n",
    "                   for predecesor, successor in sent_bigrams])\n",
    "        \n",
    "        return pmi\n",
    "    \n",
    "    def choose_highest_pmi(self, sentences: List) -> str:\n",
    "        pmis_sents = [(self.measure_pmi(sent), sent) for sent in sentences]\n",
    "        \n",
    "        _, sent = max(pmis_sents)\n",
    "        \n",
    "        return ' '.join(sent).capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random sequence of topics and coresponding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi = PMI(unigrams, bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = random.choices(TOPICS, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('malina', 'koszyk', 'zazdrość', 'morderstwo'),\n",
       " ('programowanie', 'błąd', 'zmienna', 'deklaracja'),\n",
       " ('lotniskowiec', 'łódź', 'podwodny', 'tonąć', 'atak', 'torpeda', 'ocean'))"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOPICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materializm popod bezkarne zwątpienia podstępnie chwyci pedofila vel okrutnie błaga\n",
      "Rozdzierano morganatycznego wadliwego namiastka póty asymptotycznie rozdzierano niepoczytalnego odredakcyjnego samca\n",
      "Zestrzelono ruchliwego goniącego astronautę jakoż złotawo rozbito owocowego zielonkawego mausera\n",
      "Żyrokompas popod paleniska wietrzy czujki jakoż zaatakuje kabinowe malownicze hydrazyny\n",
      "Ścigacz jmie armijne jednofunkcyjne infiltracje jakoż dokuje jednostrzałowe rurowe diabolo\n",
      "Ostrogocki spryt zrumieni vel zbiorniczek brunatno gani przerażonego glinianego warzywnego\n",
      "Poradziecki klakson przywabia jakoż pług galwanicznie zdmuchnie domorosłego śmiercionośnego sulejmana\n",
      "Niezdecydowanie obwiniano potworne obyczajowe spóźnienia tedy złośliwie nasączono poręczne emmy\n",
      "Upośledzono niejadalnego przeświadczonego suwerena póty wyszukanie przesłodzono dipolowego wektorowego instalatora\n",
      "Krzem nieomylnie indukuje tau póty wykładniczo zezna tensorowe ochrowe wola\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(pmi.choose_highest_pmi(topic_sent_gen.topic_sent_gen_n_times(10, topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = [topics.index(topic) for topic in topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your predictions here\n",
    "predictions = []\n",
    "\n",
    "if len(predictions) == len(topics):\n",
    "    accuracy_score(predictions, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
