{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar blah blah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "from operator import itemgetter\n",
    "from typing import List, Tuple, Dict\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable annoying warnings from gensim\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define nontrivial polish language grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NONTERMINALS = {\n",
    "    'S': [\n",
    "        ('VERB_PHRASE',),\n",
    "    ],\n",
    "    'VERB_PHRASE': [\n",
    "        ('VERB_IMPS',),\n",
    "        ('ADV_PHRASE', 'VERB_IMPS'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_SG_M1'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_PL_F'),\n",
    "        ('VERB_IMPS', 'ACC_PHRASE_PL_N1'),\n",
    "        ('ADV_PHRASE', 'VERB_IMPS', 'ACC_PHRASE_SG_M1'),\n",
    "        ('ADV_PHRASE', 'VERB_IMPS', 'ACC_PHRASE_PL_F'),\n",
    "        ('ADV_PHRASE', 'VERB_IMPS', 'ACC_PHRASE_PL_N2'),\n",
    "        \n",
    "    ],\n",
    "    'ADV_PHRASE': [\n",
    "        ('ADV',),\n",
    "        ('ADV', 'ADV',),\n",
    "    ],\n",
    "    'ACC_PHRASE_SG_M1': [\n",
    "        ('SUBST_SG_ACC_M1',),\n",
    "        ('ADJ_PHRASE_SG_ACC_M1', 'SUBST_SG_ACC_M1',),\n",
    "    ],\n",
    "    'ACC_PHRASE_PL_F': [\n",
    "        ('SUBST_PL_ACC_F',),\n",
    "        ('ADJ_PHRASE_PL_ACC_F_N2', 'SUBST_PL_ACC_F'),\n",
    "    ],\n",
    "    'ACC_PHRASE_PL_N2': [\n",
    "        ('SUBST_PL_ACC_N2',),\n",
    "        ('ADJ_PHRASE_PL_ACC_F_N2', 'SUBST_PL_ACC_N2'),\n",
    "    ],\n",
    "    'ADJ_PHRASE_SG_ACC_M1': [\n",
    "        ('ADJ_SG_ACC_M1',),\n",
    "        ('ADJ_SG_ACC_M1', 'ADJ_SG_ACC_M1'),\n",
    "    ],\n",
    "    'ADJ_PHRASE_PL_ACC_F_N2': [\n",
    "        ('ADJ_PL_ACC_F_N2',),\n",
    "        ('ADJ_PL_ACC_F_N2', 'ADJ_PL_ACC_F_N2'),\n",
    "    ],\n",
    "    \n",
    "    # Productions with terminals\n",
    "    'VERB_IMPS': [\n",
    "        ('verb:imps',),\n",
    "    ],\n",
    "    'SUBST_SG_ACC_M1': [\n",
    "        ('subst:sg:acc:m1',),\n",
    "    ],\n",
    "    'SUBST_PL_ACC_F': [\n",
    "        ('subst:pl:acc:f',),\n",
    "    ],\n",
    "    'SUBST_PL_ACC_N2': [\n",
    "        ('subst:pl:acc:n2',),\n",
    "    ],\n",
    "    'ADJ_SG_ACC_M1': [\n",
    "        ('adj:sg:acc:m1',),\n",
    "    ],\n",
    "    'ADJ_PL_ACC_F_N2': [\n",
    "        ('adj:pl:acc:m2.m3.f.n1.n2.p2.p3',),\n",
    "    ],\n",
    "    'ADV': [\n",
    "        ('adv:',),\n",
    "    ]\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TERMINALS = (\n",
    "    'verb:imps',\n",
    "    'subst:sg:acc:m1',\n",
    "    'subst:pl:acc:f',\n",
    "    'subst:pl:acc:n2',\n",
    "    'adj:sg:acc:m1',\n",
    "    'adj:pl:acc:m2.m3.f.n1.n2.p2.p3',\n",
    "    'adv:',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoNonterminal(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TooLongSent(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symbol:\n",
    "    def __init__(self, symbol: str):\n",
    "        self.symbol = symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Terminal(Symbol):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nonterminal(Symbol):\n",
    "    def __init__(self, symbol: str, productions: List[Symbol]):\n",
    "        super().__init__(symbol)\n",
    "        self.productions = productions\n",
    "        \n",
    "    def production(self) -> Tuple[Symbol]:\n",
    "\n",
    "        def create_new_symbol(symbol) -> Symbol:\n",
    "           if symbol in NONTERMINALS:\n",
    "               return Nonterminal(symbol, NONTERMINALS[symbol])\n",
    "           else:\n",
    "               return Terminal(symbol)\n",
    "        \n",
    "        # Draw the production\n",
    "        rand_prod_ind = np.random.choice(len(self.productions))\n",
    "        rand_prod = self.productions[rand_prod_ind]\n",
    "            \n",
    "        return list(map(create_new_symbol, rand_prod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    \n",
    "    def expand_terminal(self, symbols: List[Symbol]) -> List:        \n",
    "\n",
    "        # Extract nonterminals\n",
    "        nonterminals = [symbol for symbol in symbols\n",
    "                        if isinstance(symbol, Nonterminal)]\n",
    "            \n",
    "        if not nonterminals:\n",
    "            raise NoNonterminal\n",
    "            \n",
    "        # Expand random nonterminal\n",
    "        expand_ind = np.random.choice(len(nonterminals))\n",
    "        nonterminal = nonterminals[expand_ind]\n",
    "        new_symbols = nonterminal.production()\n",
    "            \n",
    "        # Swap nonterminal with new symbols\n",
    "        nonterminals_processed = 0\n",
    "        for ind in range(len(symbols)):\n",
    "            if isinstance(symbols[ind], Nonterminal):\n",
    "                nonterminals_processed += 1\n",
    "                    \n",
    "                if nonterminals_processed-1 == expand_ind:\n",
    "                        \n",
    "                    # Delete the old nonterminal\n",
    "                    symbols.pop(ind)\n",
    "                                \n",
    "                    # Insert new ones\n",
    "                    symbols = symbols[:ind] + new_symbols + symbols[ind:]\n",
    "\n",
    "        return symbols\n",
    "    \n",
    "    def symbols_to_strings(self, symbols: List[Symbol]) -> List:\n",
    "        return [symbol.symbol for symbol in symbols]\n",
    "        \n",
    "    def gen_terminals(self, start_symbol: Symbol) -> List:\n",
    "        symbols = [start_symbol]\n",
    "        \n",
    "        # Expand until there is any nonterminal in the symbols\n",
    "        while True:\n",
    "            try:\n",
    "                symbols = self.expand_terminal(symbols)\n",
    "            except NoNonterminal:\n",
    "                return self.symbols_to_strings(symbols)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some sentence schemas and group them by the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schemas(n_iter: int = 1000, schemas: Dict = {}) -> Dict:\n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        start_symbol = Nonterminal('S', NONTERMINALS['S'])\n",
    "        \n",
    "        schema = tuple(gen.gen_terminals(start_symbol))\n",
    "        schema_len = len(schema)\n",
    "        \n",
    "        # Update schemas\n",
    "        if schema_len in schemas:\n",
    "            schemas[schema_len].add(schema)\n",
    "        else:\n",
    "            schemas[schema_len] = {schema}\n",
    "            \n",
    "    # Map sets to tuples to enable drawing\n",
    "    schemas = {key: tuple(val) for key, val in schemas.items()}\n",
    "            \n",
    "    return schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: (('verb:imps', 'ACC_PHRASE_PL_N1'),\n",
       "  ('verb:imps', 'subst:pl:acc:f'),\n",
       "  ('adv:', 'verb:imps'),\n",
       "  ('verb:imps', 'subst:sg:acc:m1')),\n",
       " 4: (('adv:', 'adv:', 'verb:imps', 'subst:sg:acc:m1'),\n",
       "  ('adv:', 'verb:imps', 'adj:pl:acc:m2.m3.f.n1.n2.p2.p3', 'subst:pl:acc:f'),\n",
       "  ('verb:imps',\n",
       "   'adj:pl:acc:m2.m3.f.n1.n2.p2.p3',\n",
       "   'adj:pl:acc:m2.m3.f.n1.n2.p2.p3',\n",
       "   'subst:pl:acc:f'),\n",
       "  ('adv:', 'adv:', 'verb:imps', 'subst:pl:acc:f'),\n",
       "  ('adv:', 'adv:', 'verb:imps', 'subst:pl:acc:n2'),\n",
       "  ('adv:', 'verb:imps', 'adj:sg:acc:m1', 'subst:sg:acc:m1'),\n",
       "  ('verb:imps', 'adj:sg:acc:m1', 'adj:sg:acc:m1', 'subst:sg:acc:m1'),\n",
       "  ('adv:', 'verb:imps', 'adj:pl:acc:m2.m3.f.n1.n2.p2.p3', 'subst:pl:acc:n2'))}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemas = create_schemas()\n",
    "\n",
    "# Show some schemas\n",
    "dict(list(schemas.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the grammar categories found in the grammar schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolimorfGen:\n",
    "    POLIMORF_PATH = './data/polimorfologik-2.1.txt'\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.grammar_cats = dict((terminal, [])\n",
    "                                  for terminal in TERMINALS)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        with open(self.POLIMORF_PATH) as f:\n",
    "            yield from f\n",
    "            \n",
    "    def find_terminal_occ(self, line: str):\n",
    "        \"\"\"\n",
    "        Search for each pattern (terminal)\n",
    "        in the line of the polimorfologik file\n",
    "        \"\"\"\n",
    "        \n",
    "        base, token, grammar_cats = line.split(';')\n",
    "        \n",
    "        for terminal in self.grammar_cats:\n",
    "            pattern = re.compile(terminal)\n",
    "        \n",
    "            if pattern.search(grammar_cats):\n",
    "                self.grammar_cats[terminal].append((base, token))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polimorf = PolimorfGen()\n",
    "\n",
    "# Extract the categories\n",
    "for line in polimorf:\n",
    "    polimorf.find_terminal_occ(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate some sentences of length n without using the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentGen:\n",
    "    def rand_schema(self, n: int) -> Tuple:\n",
    "\n",
    "        # Draw the sentence schema\n",
    "        try:\n",
    "            schemas_n_len = schemas[n]\n",
    "            return random.choice(schemas_n_len)\n",
    "        except KeyError:\n",
    "            raise TooLongSent\n",
    "\n",
    "    def core_sent_gen(self, n: int) -> Tuple:\n",
    "        try:\n",
    "            schema = self.rand_schema(n)\n",
    "            \n",
    "            # Draw the tokens\n",
    "            tokens_with_bases = [random.choice(polimorf.grammar_cats[category])\n",
    "                                 for category in schema]\n",
    "\n",
    "            bases, tokens = list(zip(*tokens_with_bases))\n",
    "\n",
    "            return ' '.join(bases), ' '.join(tokens)\n",
    "        except TooLongSent:\n",
    "            print('Sentence too long')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_gen = SentGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('klerykowsko podirytowywać Deutsch', 'klerykowsko podirytowywano Deutscha')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bakijsko króciuśko zachachmęcić niewodnopączkowy Nowosielski',\n",
       " 'bakijsko króciuśko zachachmęcono niewodnopączkowego Nowosielskiego')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nowotysko szkarłatnie podskrobać niepodchwytliwy odchyleniowy niestrachóweckość',\n",
       " 'nowotysko szkarłatnie podskrobano niepodchwytliwe odchyleniowe niestrachóweckości')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence too long\n"
     ]
    }
   ],
   "source": [
    "sent_gen.core_sent_gen(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Word2Vec struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusGen:\n",
    "    CORPUS_PATH = './data/task3_train_segmented.txt'\n",
    "    \n",
    "    def __init__(self, n_sent):\n",
    "        self.n_sent = n_sent\n",
    "    \n",
    "    def __iter__(self):\n",
    "        with open(self.CORPUS_PATH) as f:\n",
    "            for line, _ in zip(f, range(self.n_sent)):\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('./data/word2vec.model'):\n",
    "    # Perform the embeddings only during the first session \n",
    "    \n",
    "    sentences = CorpusGen(10_000_000)\n",
    "    model = Word2Vec(sentences, min_count=1)\n",
    "    model.save('./data/word2vec.model')\n",
    "else:\n",
    "    # The model exists\n",
    "    \n",
    "    # Gensim fails in case of loading the model for the second time\n",
    "    try:\n",
    "        model\n",
    "    except NameError:\n",
    "        model = Word2Vec.load('./data/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640650"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate thematical sentences from the grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = (\n",
    "    ('malina', 'koszyk', 'zazdrość', 'morderstwo'),\n",
    "    ('programowanie', 'błąd', 'zmienna', 'deklaracja'),\n",
    "    ('lotniskowiec', 'łódź', 'podwodny',\n",
    "     'tonąć', 'atak', 'torpeda', 'ocean'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicSentGen(SentGen):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def choose_best_token(self, tokens: List, topic: Tuple) -> str:\n",
    "        \n",
    "        # Draw the topic token\n",
    "        topic_token = random.choice(topic)\n",
    "        \n",
    "        base_token_similarities = {pair: 0 for pair in tokens}\n",
    "    \n",
    "        def update_sims(pair: Tuple, token: str) -> Dict:\n",
    "            if token in self.model.wv.vocab:\n",
    "                base_token_similarities[pair] +=\\\n",
    "                    model.wv.similarity(token, topic_token)\n",
    "    \n",
    "        # For each pair similarity is a sum of\n",
    "        # similarity(base, topic_token) and similarity(token, topic_word)\n",
    "        for base, token in base_token_similarities:\n",
    "            update_sims((base, token), base)\n",
    "            update_sims((base, token), token)\n",
    "            \n",
    "        best_base, best_token = max(base_token_similarities.items(),\n",
    "                                    key=itemgetter(1))[0]\n",
    "                    \n",
    "        return best_token\n",
    "        \n",
    "    def topic_sent_gen(self, n: int, topic: Tuple,\n",
    "                       n_to_choose: int = 1000) -> str:\n",
    "        try:\n",
    "            schema = self.rand_schema(n)\n",
    "            \n",
    "            categories = [random.sample(polimorf.grammar_cats[category],\n",
    "                                        n_to_choose)\n",
    "                          for category in schema]\n",
    "            \n",
    "            topic_sent = [self.choose_best_token(category, topic)\n",
    "                          for category in categories]\n",
    "            \n",
    "            return topic_sent\n",
    "            \n",
    "        except TooLongSent:\n",
    "            print('Sentence too long')\n",
    "            \n",
    "    def topic_sent_gen_n_times(self, n: int, topic: Tuple,\n",
    "                               n_to_choose: int = 1000,\n",
    "                               n_times: int = 100) -> List:\n",
    "        \n",
    "        sents = [self.topic_sent_gen(n, topic, n_to_choose)\n",
    "                 for _ in range(n_times)]\n",
    "        \n",
    "        return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_sent_gen = TopicSentGen(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['przykładnie', 'mielono', 'wielkokwiatowe', 'miłości']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(4, TOPICS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['niedobrze', 'nieświadomie', 'uproszczono', 'absurdalne', 'okablowania']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(5, TOPICS[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bezstratnie',\n",
       " 'bojowo',\n",
       " 'przystawiono',\n",
       " 'przeciwlotniczego',\n",
       " 'kolczastego',\n",
       " 'oświetlacza']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(6, TOPICS[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence too long\n"
     ]
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen(7, TOPICS[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['najwygodniej',\n",
       "  'zaniedbanie',\n",
       "  'posądzono',\n",
       "  'drobiowe',\n",
       "  'narzeczone',\n",
       "  'awokado'],\n",
       " ['podświadomie', 'tanio', 'siano', 'boskiego', 'pojmanego', 'bananowca'],\n",
       " ['ekstra', 'jednako', 'oszukano', 'niewinne', 'melancholijne', 'Nory'],\n",
       " ['zielonkawo',\n",
       "  'czerwonawo',\n",
       "  'uwierzono',\n",
       "  'potworne',\n",
       "  'zazdrosne',\n",
       "  'pretensje'],\n",
       " ['bordo', 'purpurowo', 'wdychano', 'truskawkowe', 'srebrzyste', 'pity'],\n",
       " ['odkrycie', 'purpurowo', 'opłacono', 'najbledsze', 'mega', 'dłonie'],\n",
       " ['zaocznie', 'opętanie', 'upieczono', 'poniżające', 'samowolne', 'lilie'],\n",
       " ['umyślnie', 'okrutnie', 'kolorowano', 'perłowe', 'wielkokwiatowe', 'szynki'],\n",
       " ['skrytobójczo',\n",
       "  'dodatkowo',\n",
       "  'koszono',\n",
       "  'wiśniowe',\n",
       "  'emocjonalne',\n",
       "  'prowadnice'],\n",
       " ['marnotrawnie', 'extra', 'okazywano', 'wodoodporne', 'niesłuszne', 'gruby']]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_sent_gen.topic_sent_gen_n_times(6, TOPICS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the best topic sent with Positive Pointwise Mutual Information (PPMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create unigrams and bigrams structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGrams:\n",
    "\n",
    "    DATA_PATH = './data/poleval_2grams.txt'\n",
    "\n",
    "    def create_bigrams_unigrams(self, k: int = 100) -> Tuple:\n",
    "        \n",
    "        unigrams, bigrams = {}, {}\n",
    "        \n",
    "        def update_unigrams(token: str, freq: str) -> None:\n",
    "            if token in unigrams:\n",
    "                unigrams[token] += int(freq)\n",
    "            else:\n",
    "                unigrams[token] = int(freq)\n",
    "                \n",
    "        def update_bigrams(predecesor: str, successor: str,\n",
    "                           freq: str) -> None:\n",
    "            bigrams[(predecesor, successor)] = int(freq)\n",
    "\n",
    "        with open(self.DATA_PATH) as poleval:\n",
    "            for line in poleval:\n",
    "                freq, predecesor, successor = line.split()\n",
    "\n",
    "                # Update bigrams ans unigrams\n",
    "                if int(freq) >= k:\n",
    "                    update_bigrams(predecesor, successor, freq)\n",
    "                    update_unigrams(predecesor, freq)\n",
    "                    update_unigrams(successor, freq)\n",
    "\n",
    "        return unigrams, bigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = NGrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams, bigrams = ngrams.create_bigrams_unigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':': 1701656,\n",
       " 'dalszego': 15414,\n",
       " 'i': 12077277,\n",
       " 'prowadzenia': 76467,\n",
       " 'richard': 1695}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of unigrams\n",
    "dict(list(unigrams.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(':', 'richard'): 104,\n",
       " ('bo', 'chcemy'): 247,\n",
       " ('dalszego', 'prowadzenia'): 349,\n",
       " ('i', 'stosunek'): 137,\n",
       " ('określonych', 'ustawą'): 599}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part of bigrams\n",
    "dict(list(bigrams.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMI:\n",
    "    def __init__(self, unigrams: Dict, bigrams: Dict):\n",
    "        self.unigrams = unigrams\n",
    "        self.bigrams = bigrams\n",
    "    \n",
    "    def measure_pmi(self, sentence: List) -> float:\n",
    "        predecesors = sentence.copy()\n",
    "        successors = sentence.copy()\n",
    "        \n",
    "        predecesors.insert(0, '<BOS>')\n",
    "        successors.append('<EOS>')\n",
    "        \n",
    "        def PMI(predecesor: str, successor: str) -> float:\n",
    "            numerator = bigrams.get((predecesor, successor), 1.)\n",
    "            denominator = unigrams.get(predecesor, 1.) *\\\n",
    "                          unigrams.get(successor, 1.)\n",
    "            \n",
    "            return np.log(numerator / denominator)\n",
    "        \n",
    "        sent_bigrams = list(zip(predecesors, successors))\n",
    "        \n",
    "        pmi = sum([PMI(predecesor, successor)\n",
    "                   for predecesor, successor in sent_bigrams])\n",
    "        \n",
    "        return pmi\n",
    "    \n",
    "    def choose_highest_pmi(self, sentences: List) -> str:\n",
    "        pmis_sents = [(self.measure_pmi(sent), sent) for sent in sentences]\n",
    "        \n",
    "        _, sent = max(pmis_sents)\n",
    "        \n",
    "        return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmi = PMI(unigrams, bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wyrachowanie najtaniej solono prześliczne narkotykowe podstawki'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi.choose_highest_pmi(topic_sent_gen.topic_sent_gen_n_times(6, TOPICS[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'werbalnie traktatowo pomówiono niegrzeczne najgęstsze okablowania'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi.choose_highest_pmi(topic_sent_gen.topic_sent_gen_n_times(6, TOPICS[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'śmigło tanecznie przeklasyfikowano konfederackie wylotowe Vegety'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmi.choose_highest_pmi(topic_sent_gen.topic_sent_gen_n_times(6, TOPICS[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
